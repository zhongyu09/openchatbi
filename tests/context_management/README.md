# Context Management Test Suite

This directory contains comprehensive tests for the context management functionality in OpenChatBI.

## Test Structure

### ðŸ“ Test Files

- **`test_context_manager.py`** - Unit tests for the `ContextManager` class
- **`test_context_config.py`** - Tests for context configuration management
- **`test_agent_graph_integration.py`** - Integration tests for agent graph with context management
- **`test_edge_cases.py`** - Edge case handling
- **`test_state_operations.py`** - Tests for state operations and message processing
- **`conftest.py`** - Shared pytest fixtures and configuration
- **`test_runner.py`** - Custom test runner script

## ðŸ§ª Test Categories

### Unit Tests (`test_context_manager.py`)

Tests core functionality of the `ContextManager` class:

- âœ… Token estimation and message token calculation
- âœ… Tool output trimming (generic, SQL, Python code)
- âœ… Conversation summarization
- âœ… Context management with sliding window
- âœ… Tool wrapper functionality
- âœ… Configuration-based behavior

**Key test cases:**
- `test_trim_sql_output()` - Tests intelligent SQL result trimming
- `test_conversation_summary_success()` - Tests LLM-based summarization
- `test_manage_context_with_summarization()` - Tests full context management flow

### Configuration Tests (`test_context_config.py`)

Tests configuration management and validation:

- âœ… Default configuration values
- âœ… Custom configuration creation
- âœ… Configuration updates
- âœ… Edge cases (zero/negative values)
- âœ… Different configuration presets

**Key test cases:**
- `test_update_context_config_multiple_values()` - Tests configuration updates
- `test_production_optimized_config()` - Tests realistic production settings

### Integration Tests (`test_agent_graph_integration.py`)

Tests integration with the agent graph system:

- âœ… Agent router with context management
- âœ… Graph building with/without context management
- âœ… Tool wrapping in graph context
- âœ… Full conversation flow testing
- âœ… System message preservation

**Key test cases:**
- `test_agent_router_with_context_manager()` - Tests router integration
- `test_full_context_management_flow()` - Tests end-to-end functionality

### State Operations Tests (`test_state_operations.py`)

Tests state manipulation and message processing operations:

- âœ… Message trimming and truncation logic
- âœ… State updates and modifications
- âœ… Message type handling and conversion
- âœ… Context state preservation during operations
- âœ… Error handling in state operations

**Key test cases:**
- `test_trim_messages_by_token_count()` - Tests message trimming logic
- `test_state_message_processing()` - Tests state message operations
- `test_context_state_updates()` - Tests context state modifications

### Edge Cases (`test_edge_cases.py`)

Tests system behavior under stress and edge conditions:

- âœ… Unicode and encoding edge cases
- âœ… Malformed input handling

**Key test cases:**
- `test_sql_output_edge_cases()` - SQL edge cases
- `test_extremely_nested_or_complex_structures()` - Complex data structures

## ðŸš€ Running Tests

### Using the Test Runner

```bash
# Run all tests
python tests/context_management/test_runner.py

# Run only unit tests
python tests/context_management/test_runner.py --type unit

# Run with coverage reporting
python tests/context_management/test_runner.py --coverage
```

### Using Pytest Directly

```bash
# Run all context management tests
pytest tests/context_management/

# Run specific test file
pytest tests/context_management/test_context_manager.py

# Run with verbose output
pytest tests/context_management/ -v

# Run with coverage
pytest tests/context_management/ --cov=openchatbi.context_manager --cov-report=html
```

## ðŸ“Š Test Markers

Tests are organized using pytest markers:

- `@pytest.mark.integration` - Integration tests
- `@pytest.mark.slow` - Slow-running tests (can be excluded)

## ðŸŽ¯ Test Coverage Areas

### Core Functionality
- [x] Token estimation and management
- [x] Message processing and trimming
- [x] Conversation summarization
- [x] Context compression strategies

### Tool Output Management
- [x] SQL output trimming with structure preservation
- [x] Python code output handling
- [x] Error message preservation
- [x] Generic output trimming

### Configuration Management
- [x] Default and custom configurations
- [x] Configuration validation
- [x] Runtime configuration updates
- [x] Edge case configurations

### Integration Points
- [x] Agent router integration
- [x] Graph building integration
- [x] Tool wrapper integration
- [x] LLM service integration

### Edge Cases
- [x] Unicode and encoding issues
- [x] Malformed input handling

## ðŸ§© Fixtures

### Common Fixtures (in `conftest.py`)

- `mock_llm` - Mock language model for testing
- `standard_config` - Standard test configuration
- `minimal_config` - Minimal configuration for edge testing
- `sample_conversation` - Sample conversation data
- `large_sql_output` - Large SQL output for trimming tests
- `error_output` - Sample error output for preservation tests

## ðŸ”§ Extending Tests

### Adding New Test Cases

1. Choose the appropriate test file based on the functionality
2. Use existing fixtures from `conftest.py`
3. Follow the naming convention: `test_feature_description()`
4. Add appropriate markers for categorization

### Adding New Fixtures

Add shared fixtures to `conftest.py` if they'll be used across multiple test files.

## ðŸ› Debugging Tests

### Common Issues

1. **Mock LLM failures**: Ensure proper mocking of LLM responses
2. **Configuration conflicts**: Use isolated config instances
3. **Memory leaks in large tests**: Force garbage collection with `gc.collect()`

### Debugging Tools

```bash
# Run with debugging output
pytest tests/context_management/ -v -s

# Run single test with full traceback
pytest tests/context_management/test_name.py::test_function -v --tb=long

# Profile test performance
pytest tests/context_management/ --profile
```

## ðŸ“‹ Test Results

Expected test results:
- **Total tests**: ~100+ test cases across 6 test files
- **Coverage target**: >95% for context management modules
- **State operations tests**: All message processing should work correctly
- **Edge cases**: All should handle gracefully without crashes